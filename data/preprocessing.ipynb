{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc932bce",
   "metadata": {},
   "source": [
    "# preprocessing.ipynb\n",
    "*_______________________*\n",
    "\n",
    "In this notebook, we're going to carry out all the pre-processing work for the TCGA-GBMLGG data. This is an important part, particularly for the clinical data, and the methylome and helper functions are largely inspired by the pre-processing carried out by [Vale-Silva et al., Sci Report, 2022.](https://www.nature.com/articles/s41598-021-92799-4).\n",
    "\n",
    "The data folder and how it was constructed is available [here](https://github.com/luisvalesilva/multisurv/tree/master/data)\n",
    "\n",
    "# Table of contents\n",
    "1. [Setup & Introduction](#p1)\n",
    "2. [Clinical Data](#p2)\n",
    "3. [DNAm](#p3)\n",
    "4. [RNA](#p4)\n",
    "5. [MRI](#p5)\n",
    "6. [WSI](#p6)\n",
    "7. [Cross-validation splits](#p7)\n",
    "\n",
    "# 1. Setup & Introduction <a name=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c442cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "from typing import Tuple, Dict\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "import pyvips\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump, load\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "import json\n",
    "\n",
    "base_path = '~/TCGA/GBMLGG/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09c6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('files/clinical_data.tsv', sep='\\t')\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29268b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take only samples with brain as primary site\n",
    "dataframe = dataframe[dataframe.project_id.isin(['GBM', 'LGG'])]\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761ae217",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers function\n",
    "def request_file_info(data_type):\n",
    "    \"\"\"\n",
    "    Adapted from Vale-Silva's preprocessing.\n",
    "    \"\"\"\n",
    "    fields = [\n",
    "        'file_name',\n",
    "        'cases.submitter_id',\n",
    "        'cases.samples.sample_type',\n",
    "        'cases.project.project_id',\n",
    "        'cases.project.primary_site',\n",
    "        ]\n",
    "\n",
    "    fields = ','.join(fields)\n",
    "\n",
    "    files_endpt = 'https://api.gdc.cancer.gov/files'\n",
    "\n",
    "    filters = {\n",
    "        'op': 'and',\n",
    "        'content':[\n",
    "             {\n",
    "        \"op\": \"in\",\n",
    "        \"content\":{\n",
    "            \"field\": \"cases.project.primary_site\",\n",
    "            \"value\": [\"Brain\"]\n",
    "            }\n",
    "        },{\n",
    "            'op': 'in',\n",
    "            'content':{\n",
    "                'field': 'files.experimental_strategy',\n",
    "                'value': [data_type]\n",
    "                }\n",
    "            }  \n",
    "        ]\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'filters': filters,\n",
    "        'fields': fields,\n",
    "        'format': 'TSV',\n",
    "        'size': '200000'\n",
    "        }\n",
    "\n",
    "    response = requests.post(files_endpt, headers = {'Content-Type': 'application/json'}, json = params)\n",
    "\n",
    "    return pd.read_csv(io.StringIO(response.content.decode('utf-8')), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d2ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_patient_file_map(df, base_dir):\n",
    "    \"\"\"\n",
    "    Adapted from Vale-Silva's preprocessing.\n",
    "    \"\"\"\n",
    "    \n",
    "    d = {}\n",
    "    for _, row in df.iterrows():\n",
    "        patient = row['cases.0.submitter_id']\n",
    "        if os.path.exists(os.path.join(base_dir, row.id, row.file_name)):\n",
    "            if patient in d:\n",
    "                if not isinstance(d[patient], tuple):\n",
    "                    d[patient] = (\n",
    "                        d[patient],\n",
    "                        os.path.join(base_dir, row.id, row.file_name))\n",
    "                else:\n",
    "                    d[patient] += os.path.join(base_dir, row.id, row.file_name),\n",
    "            else:\n",
    "                d[patient] = os.path.join(base_dir, row.id, row.file_name)\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e51845",
   "metadata": {},
   "source": [
    "# 2. Clinical Data <a name=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8103fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "supplementary = pd.read_csv('files/supplementary_data.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ccc09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_clin = {\n",
    "    'patient': 'submitter_id', \n",
    "    'IDH.status': 'IDH', \n",
    "    'MGMT.promoter.status': 'MGMT',\n",
    "    'X1p.19q.codeletion': 'X1p19q',\n",
    "    'Chr.19.20.co.gain': '19.20.gain',\n",
    "    'Chr.7.gain.Chr.10.loss': '7g10l',\n",
    "    'TERT.expression.status': 'TERT',\n",
    "    'ATRX.status': 'ATRX',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1068d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "supplementary = supplementary.drop(columns=['IDH', 'Mutations', 'TERT']).rename(columns=mapper_clin)[list(mapper_clin.values())]\n",
    "supplementary = supplementary[~supplementary.duplicated(subset=['submitter_id'], keep='first')].dropna(subset='submitter_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.merge(supplementary, how='left', on='submitter_id')\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983bf56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list(mapper_clin.values()):\n",
    "    print(dataframe[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f7ba16",
   "metadata": {},
   "source": [
    "Replace abnormal values with NaNs, which will be managed later and normalize age and mutations count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba08c336",
   "metadata": {},
   "source": [
    "# 3. DNAm <a name=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e75af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "DNAm_files = request_file_info(data_type='Methylation Array')\n",
    "DNAm_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d601fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNAm_files = DNAm_files[DNAm_files['cases.0.project.project_id'].str.startswith('TCGA')]\n",
    "DNAm_files = DNAm_files[DNAm_files['file_name'].str.endswith('level3betas.txt')]\n",
    "DNAm_files = DNAm_files[DNAm_files['cases.0.samples.0.sample_type'] == 'Primary Tumor']\n",
    "DNAm_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a372610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All rows:       ', DNAm_files.shape[0])\n",
    "print('Unique patients:', DNAm_files['cases.0.submitter_id'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0f0407",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNAm_files = DNAm_files[~DNAm_files.duplicated(subset=['cases.0.submitter_id'], keep='first')]\n",
    "DNAm_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c39d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_map = make_patient_file_map(DNAm_files, base_dir=os.path.join(base_path, 'raw_DNAm'))\n",
    "file_map = {k: file_map[k] for k in file_map if k in list(dataframe['submitter_id'])}\n",
    "len(file_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d5a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNAm_mapping = pd.DataFrame([(k, v) for k, v in file_map.items()], columns=('submitter_id', 'DNAm'))\n",
    "dataframe = dataframe.merge(DNAm_mapping, how='left', on='submitter_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ef18e2",
   "metadata": {},
   "source": [
    "### Process DNAm\n",
    "Some files contain 480K probes and others only 27k, so only the probes common to both need to be kept for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878de3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_480k = pd.read_csv(os.path.join(base_path, 'raw_DNAm', 'f366f277-4079-449d-a781-0a0492a3ae41', 'e3976274-ad65-4d85-bf5c-9c10f2502748.methylation_array.sesame.level3betas.txt'), sep='\\t', index_col=0, header=None)\n",
    "sample_27k = pd.read_csv(os.path.join(base_path, 'raw_DNAm', '61fdc0ee-31d6-4051-bc1c-64feaa2e4042', 'fbc63a44-89c8-411c-87c9-05fd4138647a.methylation_array.sesame.level3betas.txt'), sep='\\t', index_col=0, header=None)\n",
    "\n",
    "probe_set = [p for p in list(sample_27k.index) if p in sample_480k.index]\n",
    "len(probe_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf41a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(base_path, 'DNAm')\n",
    "input_path = os.path.join(base_path, 'raw_DNAm')\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "for idx in tqdm.tqdm(os.listdir(input_path)):\n",
    "    if not os.path.exists(os.path.join(output_path, idx)):\n",
    "        os.makedirs(os.path.join(output_path, idx))\n",
    "        \n",
    "    files = os.listdir(os.path.join(input_path, idx))\n",
    "    filename = [file for file in files if 'level3betas.txt' in file][0]\n",
    "    temp_df = pd.read_csv(os.path.join(input_path, idx, filename), sep='\\t', index_col=0, header=None, names=['Composite Element REF', 'Beta_value'])\n",
    "    temp_df = temp_df[temp_df.index.isin(probe_set)]\n",
    "    temp_df.to_csv(os.path.join(output_path, idx, filename.replace('txt', 'csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f708fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_dnam(x):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    else:\n",
    "        return str(x).replace('raw_DNAm', 'DNAm').replace('txt', 'csv')\n",
    "    \n",
    "    \n",
    "dataframe['DNAm'] = dataframe['DNAm'].apply(replace_dnam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a767e95d",
   "metadata": {},
   "source": [
    "# 4. RNASeq <a name=\"p4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634df151",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mRNA_files = request_file_info(data_type='RNA-Seq')\n",
    "mRNA_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab26f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mRNA_files = mRNA_files[mRNA_files['cases.0.project.project_id'].str.startswith('TCGA')]\n",
    "mRNA_files = mRNA_files[mRNA_files['file_name'].str.endswith('rna_seq.augmented_star_gene_counts.tsv')]\n",
    "mRNA_files = mRNA_files[mRNA_files['cases.0.samples.0.sample_type'] == 'Primary Tumor']\n",
    "mRNA_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d83eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All rows:       ', mRNA_files.shape[0])\n",
    "print('Unique patients:', mRNA_files['cases.0.submitter_id'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a6184",
   "metadata": {},
   "outputs": [],
   "source": [
    "mRNA_files = mRNA_files[~mRNA_files.duplicated(subset=['cases.0.submitter_id'], keep='first')]\n",
    "mRNA_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_map = make_patient_file_map(mRNA_files, os.path.join(base_path, 'raw_RNA'))\n",
    "file_map = {k: file_map[k] for k in file_map if k in list(dataframe['submitter_id'])}\n",
    "len(file_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNA_mapping = pd.DataFrame([(k, v) for k, v in file_map.items()], columns=('submitter_id', 'RNA'))\n",
    "dataframe = dataframe.merge(RNA_mapping, how='left', on='submitter_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4493718a",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "In this section, we only consider genes coding for proteins, and we also remove genes with a variance of less than 0.1 on the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315abb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_file_RNA(path):\n",
    "    temp_df = pd.read_csv(path, sep='\\t', skiprows=6, usecols=[0, 2, 8], names=['gene_id', 'gene_type', 'fpkm_uq_unstranded']).set_index('gene_id')#, 2, 3, 4, 5, 6, 7, 8])\n",
    "    temp_df = temp_df[temp_df['gene_type'] == 'protein_coding']['fpkm_uq_unstranded']\n",
    "    return temp_df\n",
    "\n",
    "dataframe_train = dataframe[dataframe.group == 'train']\n",
    "file_map_train = make_patient_file_map(mRNA_files, os.path.join(base_path, 'raw_RNA'))\n",
    "file_map_train = {k: file_map[k] for k in file_map if k in list(dataframe_train['submitter_id'])}\n",
    "len(file_map_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabf75a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_train_dataframe = pd.concat([load_single_file_RNA(path) for path in file_map_train.values()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0852e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_description = rna_train_dataframe.T.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbeb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_to_keep = gene_description.columns[gene_description.iloc[2, :] > 0.1].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e862d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_single_file_RNA(path, genes_to_keep=genes_to_keep):\n",
    "    temp_df = load_single_file_RNA(path)\n",
    "    return temp_df.loc[genes_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f6b84a",
   "metadata": {},
   "source": [
    "Copy clean dataframes ready for use to a new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71d5dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(base_path, 'RNA')\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "for patient, filepath in tqdm.tqdm(file_map.items()):\n",
    "    idx, filename = filepath.split('/')[-2:]\n",
    "    if not os.path.exists(os.path.join(output_path, idx)):\n",
    "        os.makedirs(os.path.join(output_path, idx))\n",
    "        \n",
    "    temp_df = load_preprocessed_single_file_RNA(filepath)\n",
    "    temp_df.to_csv(os.path.join(output_path, idx, filename.replace('tsv', 'csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02afab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_rna(x):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    else:\n",
    "        return str(x).replace('raw_RNA', 'RNA').replace('tsv', 'csv')\n",
    "    \n",
    "    \n",
    "dataframe['RNA'] = dataframe['RNA'].apply(replace_rna)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e1418",
   "metadata": {},
   "source": [
    "# 5. MRI <a name=\"p5\"></a>\n",
    "For this part, we are using the overlap with patients from the BraTS and TCGA competitions, using the mapping file available on the competition website. Since the BraTS competition contains over a thousand cases and only 165 from the TCGA, we will first of all pre-train the models on the MRIs using a contrastive technique ([SimCLR](https://arxiv.org/abs/2002.05709)) inspired by the [MONAI tutorial](https://github.com/Project-MONAI/tutorials/tree/main/self_supervised_pretraining/vit_unetr_ssl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e9bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_file = 'mappings/BraTS2023_2017_GLI_Mapping.xlsx'\n",
    "mapping_mri = pd.read_excel(mapping_file)\n",
    "mapping_mri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a35ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_mri = mapping_mri[mapping_mri['Cohort Name (if publicly available)'].str.contains('TCGA')]\n",
    "mapping_mri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267acda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_map = {tcga_idx: os.path.join(base_path, 'MRI', brats_idx) for tcga_idx, brats_idx in zip(mapping_mri['Local ID '], mapping_mri['BraTS2021'])}\n",
    "file_map = {k: file_map[k] for k in file_map if k in list(dataframe['submitter_id'])}\n",
    "len(file_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "MRI_mapping = pd.DataFrame([(k, v) for k, v in file_map.items()], columns=('submitter_id', 'MRI'))\n",
    "dataframe = dataframe.merge(MRI_mapping, how='left', on='submitter_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc95b60",
   "metadata": {},
   "source": [
    "Since the segmentation masks are also supplied and to reduce the complexity of calculating the 3D convolutions, several scenarios have been devised: training on the entire volume, training on a volume centred around the tumour, using all the modalities or just FLAIR and T1wCE.\n",
    "\n",
    "To pre-train, simply go to the root of the project and perform the following CLI:\n",
    "```\n",
    "$ python -m data.run_mri_pretraining\n",
    "```\n",
    "\n",
    "**NB**: Numerous hyperparameters can be modified, such as the modalities used, whether the entire volume or just the tumour is viewed, etc...\n",
    "\n",
    "In this work, we choose to freeze the encoder and extract embeddings from tumour-centred data with Flair and T1ce modalities. To do this, you can use the python script provided.\n",
    "\n",
    "```\n",
    "$ python -m data.extract_brain_embeddings\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b4a92",
   "metadata": {},
   "source": [
    "# 6. WSI <a name=\"p6\"></a>\n",
    "\n",
    "This part is much more complex than the previous ones, and the entire processing pipeline is described below.\n",
    "First of all, as the WSIs take up a lot of storage space, those of the LGG project and those of the GBM project are stored on separate disks (code to be adapted according to each case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221cecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "wsi_files = request_file_info(data_type='Diagnostic Slide')\n",
    "wsi_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a37ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b70feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_files = wsi_files[wsi_files['cases.0.project.project_id'].str.startswith('TCGA')]\n",
    "wsi_files = wsi_files[wsi_files['file_name'].str.endswith('.svs')]\n",
    "wsi_files = wsi_files[wsi_files['cases.0.samples.0.sample_type'] == 'Primary Tumor']\n",
    "wsi_files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e99da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All rows:       ', wsi_files.shape[0])\n",
    "print('Unique patients:', wsi_files['cases.0.submitter_id'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f14a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_map_gbm = make_patient_file_map(wsi_files, '/media/hddext/medical/TCGA-GBM_WSI/')\n",
    "file_map_gbm = {k: file_map_gbm[k] for k in file_map_gbm if k in list(dataframe['submitter_id'])}\n",
    "len(file_map_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b1a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_map_lgg = make_patient_file_map(wsi_files, '/archive/medical/tcga_lgg/wsi/')\n",
    "file_map_lgg = {k: file_map_lgg[k] for k in file_map_lgg if k in list(dataframe['submitter_id'])}\n",
    "len(file_map_lgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef52aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_map = {**file_map_gbm, **file_map_lgg}\n",
    "len(file_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c08f0d7",
   "metadata": {},
   "source": [
    "### Create thumbnails and masks\n",
    "\n",
    "To create lower-resolution images and the corresponding mask, which can then be used to patch in the required areas.\n",
    "\n",
    "To create the mask, we'll use [OTSU filtering](https://www.researchgate.net/publication/202972407_Survey_over_image_thresholding_techniques_and_quantitative_performance_evaluation) and HSV conversion to filter out felt-tip marks.\n",
    "To do this, simply use the command line:\n",
    "```\n",
    "$ python get_wsi_thumbnails.py -p PATH/TO/YOUR/DATA\n",
    "```\n",
    "**In this case, as the LGGs were stored elsewhere than the GBMs, This script is used twice, once on each folder.**\n",
    "\n",
    "### Select only one slide per each patient\n",
    "For many patients, there are several slides, up to 9. For the sake of simplicity here and to eliminate as much noisy data as possible (with felt-tip markers, air bubbles, etc.), the small code below plots the corresponding thumbnail for each patient with several slides. An arbitrary choice is made (see `wsi_mapping.json`), keeping the best quality, flawless, wide and heterogeneous images. \n",
    "\n",
    "**Be careful, The slide index starts at zero!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2path = {}\n",
    "for patient_id, path in file_map.items():\n",
    "    if isinstance(path, tuple):\n",
    "        n_slides = len(path)\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        for i in range(n_slides):\n",
    "            plt.subplot(1, n_slides, i+1)\n",
    "            plt.axis('off')\n",
    "            plt.title(pyvips.Image.new_from_file(path[i]).get('aperio.AppMag'))\n",
    "            thumbnail_path = '/'.join(path[i].split('/')[:-1])\n",
    "            thumbnail = np.array(Image.open(os.path.join(thumbnail_path, 'thumbnail.jpg')))\n",
    "            plt.imshow(thumbnail)\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        plt.show()\n",
    "        idx = int(input())\n",
    "        id2path[patient_id] = path[idx]\n",
    "    else:\n",
    "        id2path[patient_id] = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f1221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('mappings/wsi_mapping.json', 'w') as f:\n",
    "    # write the dictionary to the file in JSON format\n",
    "    json.dump(id2path, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7007adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mappings/wsi_mapping.json', 'r') as f:\n",
    "    wsi_mapping = json.load(f)\n",
    "    \n",
    "WSI_mapping = pd.DataFrame([(k, v) for k, v in wsi_mapping.items()], columns=('submitter_id', 'WSI'))\n",
    "dataframe = dataframe.merge(WSI_mapping, how='left', on='submitter_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc1c8dd",
   "metadata": {},
   "source": [
    "# Extract patches\n",
    "\n",
    "The first step is to extract patches for each patient. For each WSI, $n$ patches of size $s \\times s$ are extracted from the low-resolution tissue mask. From these $n$ patches, we choose to keep only the $k$ with the best scores. Each patch is converted to HSV and a filter is applied to retain only the cells, from which the score is deduced. The code below illustrates this strategy with a single slide and with $n=10$ and $k=5$.\n",
    "\n",
    "**NB: In our experiments**\n",
    "$n = 1000$\n",
    "$s = 256$\n",
    "$k = 100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42bcfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## take a random slide\n",
    "path = '/archive/medical/tcga_lgg/wsi/'\n",
    "paths = os.listdir(path)\n",
    "p = os.path.join(path, paths[1])\n",
    "files = os.listdir(p)\n",
    "wsi = os.path.join(path, p, [f for f in files if f.endswith('svs')][0])\n",
    "slide = pyvips.Image.new_from_file(wsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f63621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masked_hsv(patch: np.ndarray):\n",
    "    patch = cv2.cvtColor(patch, cv2.COLOR_RGB2HSV)\n",
    "    mask = np.tile(patch[:,:,1] > 150, (3, 1, 1)).transpose(1,2,0) * np.tile(patch[:,:,2] < 150, (3, 1, 1)).transpose(1,2,0)\n",
    "    return patch*mask\n",
    "\n",
    "class PatchExtractor:\n",
    "    '''\n",
    "    This is slightly modified version of the true patch extractor.\n",
    "    These modifications are done for visualization purposes...\n",
    "    '''\n",
    "    def __init__(self, num_patches, patch_size, iterations, s_min: int = 150, v_max: int = 150):\n",
    "        self.num_patches = num_patches\n",
    "        self.patch_size = patch_size\n",
    "        self.iterations = iterations\n",
    "        self.s_min = s_min\n",
    "        self.v_max = v_max\n",
    "    \n",
    "    def patch_to_score(self, patch: np.ndarray):\n",
    "        mask = np.tile(patch[:,:,1] > self.s_min, (3, 1, 1)).transpose(1,2,0) * np.tile(patch[:,:,2] < self.v_max, (3, 1, 1)).transpose(1,2,0)\n",
    "        return (mask.sum(-1)/3).sum()\n",
    "\n",
    "    @staticmethod\n",
    "    def _from_idx_to_row_col(idx, width):\n",
    "        row = (idx // width)\n",
    "        col = (idx % width) \n",
    "        return (row, col)\n",
    "    \n",
    "    \n",
    "    def __call__(self, slide, mask):\n",
    "        patches_buffer = {}\n",
    "        idx_buffer = {}\n",
    "        factor = int(slide.width / mask.shape[1])\n",
    "        delta = int(self.patch_size / factor)\n",
    "        mask = torch.from_numpy(mask).unsqueeze(0).unsqueeze(0).float()\n",
    "        kernel = torch.ones(1, 1, delta, delta)\n",
    "        probabilities = F.conv2d(mask, kernel, stride=(delta, delta))\n",
    "        probabilities = probabilities.squeeze()\n",
    "        n_samples = torch.argwhere(probabilities).size(0) if torch.argwhere(probabilities).size(0) < self.iterations else self.iterations\n",
    "        indexes = torch.multinomial(probabilities.view(-1), n_samples, replacement=False)\n",
    "        for idx in indexes:\n",
    "            patch, idx = self._from_idx_to_patch(slide, idx, probabilities.size(1))\n",
    "            score = int(self.patch_to_score(cv2.cvtColor(patch, cv2.COLOR_RGB2HSV)))\n",
    "            patches_buffer[score] = patch\n",
    "            patches_buffer = dict(sorted(patches_buffer.items(), key=lambda x: x[0], reverse=True))\n",
    "            idx_buffer[score] = idx\n",
    "            idx_buffer = dict(sorted(idx_buffer.items(), key=lambda x: x[0], reverse=True))\n",
    "            #patches_buffer = dict(itertools.islice(patches_buffer.items(), self.num_patches))\n",
    "        \n",
    "        return patches_buffer, idx_buffer\n",
    "    \n",
    "    def _from_idx_to_patch(self, slide, idx, width):\n",
    "        idx = self._from_idx_to_row_col(idx, width)\n",
    "        row = idx[0] * self.patch_size\n",
    "        col = idx[1] * self.patch_size\n",
    "        region = slide.crop(int(col), int(row), self.patch_size, self.patch_size)\n",
    "        patch = np.ndarray(buffer=region.write_to_memory(),\n",
    "                                dtype=np.uint8,\n",
    "                                shape=(region.height, region.width, region.bands))\n",
    "        \n",
    "        return cv2.cvtColor(patch, cv2.COLOR_RGBA2RGB), idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2b3682",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import torch.nn.functional as F\n",
    "extractor = PatchExtractor(5, 512, 10, 130, 170)\n",
    "patches, idx = extractor(slide, np.load('/'.join(slide.filename.split('/')[:-1] + ['mask.npy'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f2cb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validated_patches = {k: patches[k] for k in list(patches.keys())[:5]}\n",
    "validated_index = {k: idx[k] for k in list(idx.keys())[:5]}\n",
    "discarded_patches = {k: patches[k] for k in list(patches.keys())[5:]}\n",
    "discarded_index = {k: idx[k] for k in list(idx.keys())[5:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61394bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "plt.suptitle('Selected patches', y=0.6, fontsize=20)\n",
    "for i, (score, patch) in enumerate(validated_patches.items()):\n",
    "    plt.subplot(2, len(validated_patches), i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(patch)\n",
    "    plt.subplot(2, len(validated_patches), (i+1)+len(validated_patches))\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Score: {score}', fontsize=16)\n",
    "    plt.imshow(get_masked_hsv(patch))\n",
    "plt.subplots_adjust(\n",
    "                    top=0.55, \n",
    "                    wspace=0.1, \n",
    "                    hspace=0.1)\n",
    "plt.show()\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.suptitle('Discarded patches', y=0.6, fontsize=20)\n",
    "for i, (score, patch) in enumerate(discarded_patches.items()):\n",
    "    plt.subplot(2, len(discarded_patches), i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(patch)\n",
    "    plt.subplot(2, len(discarded_patches), (i+1)+len(discarded_patches))\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Score: {score}', fontsize=16)\n",
    "    plt.imshow(get_masked_hsv(patch))\n",
    "plt.subplots_adjust(\n",
    "                    top=0.55, \n",
    "                    wspace=0.1, \n",
    "                    hspace=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de76fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnail = np.array(Image.open('/'.join(slide.filename.split('/')[:-1] + ['thumbnail.jpg'])))\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(thumbnail)\n",
    "plt.axis('off')\n",
    "plt.scatter(np.array(list(validated_index.values()))[:, 1] * 4, np.array(list(validated_index.values()))[:, 0] * 4, color='limegreen', marker='X', s=100)\n",
    "plt.scatter(np.array(list(discarded_index.values()))[:, 1] * 4, np.array(list(discarded_index.values()))[:, 0] * 4, color='red', marker='X', s=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627878b8",
   "metadata": {},
   "source": [
    "In the figure above, the red crosses are the patches that have not been retained and the others are those that have been retained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c520d69",
   "metadata": {},
   "source": [
    "# Extraction job\n",
    "\n",
    "This is where the patch extraction code resides. Note that some slides have a magnification of **x40** and others **x20**. To have the same resolution for each patient and work at iso-micron-per-pixel, patches of size $2s \\times 2s$ are extracted and then downsampled before being scored for slides with **x40** magnification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578abe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchExtractor:\n",
    "    def __init__(self, num_patches, patch_size, iterations, s_min: int = 120, v_max: int = 150, v_min: int = 40):\n",
    "        self.num_patches = num_patches\n",
    "        self.patch_size = patch_size\n",
    "        self.iterations = iterations\n",
    "        self.s_min = s_min\n",
    "        self.v_max = v_max\n",
    "        self.v_min = v_min\n",
    "    \n",
    "    def patch_to_score(self, patch: np.ndarray) -> int:\n",
    "        mask = np.tile(patch[:,:,1] > self.s_min, (3, 1, 1)).transpose(1,2,0) * np.tile(patch[:,:,2] < self.v_max, (3, 1, 1)).transpose(1,2,0) * np.tile(patch[:,:,2] > self.v_min, (3, 1, 1)).transpose(1,2,0)\n",
    "        return (mask.sum(-1)/3).sum()\n",
    "\n",
    "    @staticmethod\n",
    "    def _from_idx_to_row_col(idx: int, width: int) -> Tuple[int, int]:\n",
    "        row = (idx // width)\n",
    "        col = (idx % width) \n",
    "        return (row, col)\n",
    "    \n",
    "    \n",
    "    def __call__(self, slide: pyvips.Image, mask: np.ndarray) -> Dict[int, np.ndarray]:\n",
    "        patches_buffer = {}\n",
    "        factor = int(slide.width / mask.shape[1])\n",
    "        delta = int(self.patch_size / factor)\n",
    "        if delta == 3:\n",
    "            delta = 4\n",
    "        mask = torch.from_numpy(mask).unsqueeze(0).unsqueeze(0).float()\n",
    "        kernel = torch.ones(1, 1, delta, delta)\n",
    "        probabilities = F.conv2d(mask, kernel, stride=(delta, delta))\n",
    "        probabilities = probabilities.squeeze()\n",
    "        if torch.argwhere(probabilities).size(0) < self.num_patches:\n",
    "            print(f'The mask was too small ({torch.argwhere(probabilities).size(0)}), so you could pick anywhere in the slide')\n",
    "            probabilities = torch.ones_like(probabilities)\n",
    "            print(f'Number of potential patches now: {torch.argwhere(probabilities).size(0)}')\n",
    "        n_samples = torch.argwhere(probabilities).size(0) if torch.argwhere(probabilities).size(0) < self.iterations else self.iterations\n",
    "        indexes = torch.multinomial(probabilities.view(-1), n_samples, replacement=False)\n",
    "        for idx in indexes:\n",
    "            patch = self._from_idx_to_patch(slide, idx, probabilities.size(1))\n",
    "            if self.patch_size == 512:\n",
    "                patch = cv2.resize(patch, (256, 256))\n",
    "            score = self.patch_to_score(cv2.cvtColor(patch, cv2.COLOR_RGB2HSV))\n",
    "            if score in list(patches_buffer.keys()):\n",
    "                score += random.random()\n",
    "            patches_buffer[score] = patch\n",
    "            patches_buffer = dict(sorted(patches_buffer.items(), key=lambda x: x[0], reverse=True))\n",
    "            patches_buffer = dict(itertools.islice(patches_buffer.items(), self.num_patches))\n",
    "        \n",
    "        return patches_buffer\n",
    "    \n",
    "    def _from_idx_to_patch(self, slide: pyvips.Image, idx: int, width: int) -> np.ndarray:\n",
    "        idx = self._from_idx_to_row_col(idx, width)\n",
    "        row = idx[0] * self.patch_size\n",
    "        col = idx[1] * self.patch_size\n",
    "        region = slide.crop(int(col), int(row), self.patch_size, self.patch_size)\n",
    "        patch = np.ndarray(buffer=region.write_to_memory(),\n",
    "                                dtype=np.uint8,\n",
    "                                shape=(region.height, region.width, region.bands))\n",
    "        \n",
    "        return cv2.cvtColor(patch, cv2.COLOR_RGBA2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de865b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "mapping_path = 'wsi_mapping.json'\n",
    "mapping = json.load(open(mapping_path, 'r'))\n",
    "num_patches = 100\n",
    "iterations = 1000\n",
    "patch_size = 256\n",
    "for patient, wsi_path in tqdm.tqdm(mapping.items()):\n",
    "    folder = '/'.join(wsi_path.split('/')[:-1])\n",
    "    if os.path.exists(os.path.join(folder, 'patches')) and len(os.listdir(os.path.join(folder, 'patches'))) == num_patches:\n",
    "        print('Done for patient: ', patient)\n",
    "        continue\n",
    "    slide = pyvips.Image.new_from_file(wsi_path)\n",
    "    if int(float(slide.get('aperio.AppMag'))) == 40:\n",
    "        extractor = PatchExtractor(num_patches=num_patches, patch_size=patch_size*2, iterations=iterations, s_min=130, v_max=170)\n",
    "    else:\n",
    "        extractor = PatchExtractor(num_patches=num_patches, patch_size=patch_size, iterations=iterations, s_min=130, v_max=170)\n",
    "    mask = np.load(os.path.join(folder, 'mask.npy'))\n",
    "    patches = extractor(slide, mask)\n",
    "    if not os.path.exists(os.path.join(folder, 'patches')):\n",
    "        os.makedirs(os.path.join(folder, 'patches'))\n",
    "    \n",
    "    if len(patches) != 100:\n",
    "        print(patient, len(patches))\n",
    "    for i, (score, patch) in enumerate(patches.items()):\n",
    "        patch = Image.fromarray(patch)\n",
    "        patch.save(os.path.join(folder, 'patches', f'{int(i)}_{int(score)}.png'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952cc19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "for patient, wsi_path in tqdm.tqdm(mapping.items()):\n",
    "    folder = '/'.join(wsi_path.split('/')[:-1])\n",
    "    if len(os.listdir(os.path.join(folder, 'patches'))) != 100:\n",
    "        print('Abnormal number of patches')\n",
    "    \n",
    "    patches = os.listdir(os.path.join(folder, 'patches'))\n",
    "    for patch in patches:\n",
    "        patch = os.path.join(folder, 'patches', patch)\n",
    "        patch = np.array(Image.open(patch))\n",
    "        if patch.shape != (256, 256, 3):\n",
    "            print('Abnormal patch size, expected (256, 256, 3) got {patch.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacf454e",
   "metadata": {},
   "source": [
    "# Self-supervised contrastive training\n",
    "\n",
    "To reduce the dimensionality of the WSIs, we already carry out a pre-training on the patches extracted, which will be used to extract for each patient k (100 in our case) embedding of size 512 or 1024. Here we use a ResNet34 that we train with the SimCLR framework.\n",
    "\n",
    "To do this, simply go to the root of the project and run the CLI:\n",
    "\n",
    "```\n",
    "$ python -m data.run_wsi_pretraining\n",
    "```\n",
    "\n",
    "Batch size, number of gpus, learning rate and weight decay can be adjusted on the command line. <br>\n",
    "Once that's done, we retrieve the pre-trained model `models/wsi_encoder.pth` and we infer all these patches for each patient, which we store in a dataframe in the format $k \\times e_{dim}$\n",
    "\n",
    "# Embeddings extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbb655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_state_dict(state_dict):\n",
    "    new_state_dict = {}\n",
    "    for key, value in state_dict.items():\n",
    "        if 'module.encoder' in key:\n",
    "            new_state_dict[key[15:]] = value\n",
    "        else:\n",
    "            new_state_dict[key] = value\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "extractor = torchvision.models.resnet34()\n",
    "extractor.fc = torch.nn.Identity()\n",
    "state_dict = clean_state_dict(torch.load('./models/wsi_encoder.pth'))\n",
    "extractor.load_state_dict(state_dict, strict=False)\n",
    "extractor.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0690e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mappings/wsi_mapping.json', 'r') as f:\n",
    "    mapping = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6342be9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_path = os.path.join(base_path, 'WSI')\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "file_map = {}\n",
    "for patient, path in tqdm.tqdm(mapping.items(), total=len(mapping)):\n",
    "    idx = path.split('/')[-2]\n",
    "    patches_path = os.path.join('/'.join(path.split('/')[:-1]), 'patches')\n",
    "    patches = os.listdir(patches_path)\n",
    "    patches = [ToTensor()(np.array(Image.open(os.path.join(patches_path, patch)))) for patch in patches]\n",
    "    patches = torch.stack(patches)\n",
    "    with torch.no_grad():\n",
    "        embeddings = extractor(patches)\n",
    "        \n",
    "    temp_df = pd.DataFrame(embeddings)\n",
    "    final_path = os.path.join(output_path, idx, f'{patient}.csv')\n",
    "    temp_df.to_csv(final_path, index=False)\n",
    "    file_map[patient] = final_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(base_path, 'WSI')\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "file_map = {}\n",
    "i=0\n",
    "extractor.eval()\n",
    "for patient, path in tqdm.tqdm(mapping.items(), total=len(mapping)):\n",
    "    i+=1\n",
    "    idx = path.split('/')[-2]\n",
    "    if not os.path.exists(os.path.join(output_path, idx)):\n",
    "        os.makedirs(os.path.join(output_path, idx))\n",
    "    patches_path = os.path.join('/'.join(path.split('/')[:-1]), 'patches')\n",
    "    patches = os.listdir(patches_path)\n",
    "    patches = [ToTensor()(np.array(Image.open(os.path.join(patches_path, patch)))) for patch in patches]\n",
    "    patches = torch.stack(patches)\n",
    "    with torch.no_grad():\n",
    "        embeddings = extractor(patches)\n",
    "    \n",
    "    temp_df = pd.DataFrame(embeddings)\n",
    "    final_path = os.path.join(output_path, idx, f'{patient}.csv')\n",
    "    temp_df.to_csv(final_path, index=False)\n",
    "    file_map[patient] = final_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc19a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "WSI_mapping = pd.DataFrame([(k, v) for k, v in file_map.items()], columns=('submitter_id', 'WSI'))\n",
    "dataframe.drop(columns=['WSI'], inplace=True)\n",
    "dataframe = dataframe.merge(WSI_mapping, how='left', on='submitter_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f395f4",
   "metadata": {},
   "source": [
    "# 7. Cross-validation splits <a name=\"p7\"></a>\n",
    "We choose to perform a StratifiedKFold with $k = 5$, the stratification is done using the `project_id` criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3430044f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_brain = dataframe[dataframe.group == 'train']\n",
    "test_brain = dataframe[dataframe.group == 'test']\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2023)\n",
    "splits = np.zeros(len(train_brain))\n",
    "for i, (_, fold_idx) in enumerate(skf.split(train_brain, train_brain.project_id)):\n",
    "    splits[fold_idx] = i\n",
    "\n",
    "\n",
    "train_brain['split'] = splits.astype(int)\n",
    "\n",
    "# sanity check\n",
    "project_id = []\n",
    "modalities = []\n",
    "event = []\n",
    "for i in range(5):\n",
    "    temp_df = train_brain[train_brain.split == int(i)]\n",
    "    project_id.append(dict(temp_df.project_id.value_counts()))\n",
    "    event.append(dict(temp_df.event.value_counts()))\n",
    "    print(f'Project id: {dict(temp_df.project_id.value_counts())}')\n",
    "    print(f'Ratio censored/non_censored: {temp_df.event.value_counts()}')\n",
    "    temp_modalities = {}\n",
    "    for modality in ['RNA', 'DNAm', 'MRI', 'WSI']:\n",
    "        temp_modalities[modality] = sum(temp_df[modality].isna()) / len(temp_df)\n",
    "    modalities.append(temp_modalities)\n",
    "    plt.hist(temp_df.time.values)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d282888",
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e1d6ca",
   "metadata": {},
   "source": [
    "## RNA Scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1481b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def log_transform(x):\n",
    "    return np.log(x + 1)\n",
    "\n",
    "for split in train_brain.split.unique():\n",
    "    temp_df = train_brain[train_brain.split != int(split)]\n",
    "    temp_df = pd.concat([pd.read_csv(path).set_index('gene_id') for path in temp_df.RNA if not pd.isna(path)], axis=1).T\n",
    "    print(temp_df.shape)\n",
    "    scaler = StandardScaler()\n",
    "    log = FunctionTransformer(log_transform)\n",
    "    pipe = Pipeline(steps=[('log', log) , ('scaler', scaler)])\n",
    "    pipe.fit(temp_df.values)\n",
    "    dump(pipe, f'rna_preprocessors/trf_{int(split)}.joblib')\n",
    "    print('Done for split: ', int(split))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405f4537",
   "metadata": {},
   "source": [
    "## One last word to conclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dedd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_brain = train_brain.drop(columns=['group', 'Unnamed: 0', 'days_to_last_follow_up', 'vital_status', 'days_to_death'])\n",
    "test_brain = test_brain.drop(columns=['group', 'Unnamed: 0', 'days_to_last_follow_up', 'vital_status', 'days_to_death'])\n",
    "train_brain.to_csv('files/train_brain.csv', index=False)\n",
    "test_brain.to_csv('files/test_brain.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('files/dataframe_brain.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
